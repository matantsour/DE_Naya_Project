{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f1d3df4-da23-42a6-9bc6-a28461c554f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, DoubleType, BooleanType, TimestampType\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0934361-7560-4fe1-802a-6827aabf1bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_missing_locations_longitude_latitude_dict(missing_locations_longitude_latitude):\n",
    "    # Dictionary to store results\n",
    "    missing_locations_longitude_latitude_dict = {}\n",
    "    \n",
    "    # Nominatim requires a custom User-Agent\n",
    "    headers = {\n",
    "        \"User-Agent\": \"MyReverseGeocoder/1.0\"\n",
    "    }\n",
    "    \n",
    "    for lon, lat in missing_locations_longitude_latitude:\n",
    "        url = f\"https://nominatim.openstreetmap.org/reverse?lat={lat}&lon={lon}&format=json\"\n",
    "        try:\n",
    "            response = requests.get(url, headers=headers)\n",
    "            if response.status_code == 200:\n",
    "                results = response.json()\n",
    "                results = {'city': results['address'].get('city',results['address'].get('town',results['address'].get('road'))),\\\n",
    "                            'county': results['address']['county'],\\\n",
    "                            'state': results['address']['state'],\\\n",
    "                            'country': results['address']['country_code'].upper()}\n",
    "                missing_locations_longitude_latitude_dict[(lon, lat)] = results\n",
    "            else:\n",
    "                print(f\"Failed for {(lon, lat)}: {response.status_code}\")\n",
    "                missing_locations_longitude_latitude_dict[(lon, lat)] = None\n",
    "        except Exception as e:\n",
    "            print(f\"Error for {(lon, lat)}: {e}\\n{url}\")\n",
    "            missing_locations_longitude_latitude_dict[(lon, lat)] = None\n",
    "        \n",
    "        time.sleep(1)\n",
    "    \n",
    "    return missing_locations_longitude_latitude_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b92bd5b1-aac5-41ee-aca9-66623e229985",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/14 20:01:52 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/08/14 20:01:57 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- created: timestamp (nullable = true)\n",
      " |-- location_display_name: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- county: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      " |-- contract_time: string (nullable = true)\n",
      " |-- contract_type: string (nullable = true)\n",
      " |-- category_tag: string (nullable = true)\n",
      " |-- category_label: string (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- salary_is_predicted: boolean (nullable = true)\n",
      " |-- salary_min: double (nullable = true)\n",
      " |-- salary_max: double (nullable = true)\n",
      " |-- redirect_url: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName('adzuna_stage_2') \\\n",
    "    .getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"WARN\")\n",
    "jobs = spark.read.parquet(\"s3a://naya-project-job-ads/data/stages/adzuna/stage_1/2025/08/14/\")\n",
    "jobs.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50b592a1-8769-4b54-ac42-85c30ed32491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#Check if duplicate ids exists:\n",
    "n = jobs.count()\n",
    "n_1 = jobs.dropDuplicates([\"id\"]).count()\n",
    "if n>n_1:\n",
    "    print(f\"some duplicate ids exists: {n-n_1} duplicate ids\\nRemoving duplicate ids\")\n",
    "    jobs = jobs.dropDuplicates([\"id\"])\n",
    "\n",
    "n_null_created = jobs.filter(F.col(\"created\").isNull()).count()\n",
    "if n_null_created>0:\n",
    "    window_spec = Window.orderBy(\"created\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "    jobs = jobs.withColumn(\n",
    "    \"created\",\n",
    "    F.last(\"created\", ignorenulls=True).over(window_spec)\n",
    ")\n",
    "jobs = jobs.withColumn('created',F.col('created').cast(StringType()))\n",
    "jobs = jobs.filter(~(F.col(\"latitude\").isNull() | F.col(\"longitude\").isNull()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e45c5a-8bd1-4735-99bf-a97fa2b56585",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c53a20fb-c7b2-4174-8ede-23f52f11c10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = jobs.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "79a77fb1-52a3-4033-a892-8232b0162ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "state\n",
      "county\n",
      "city\n",
      "contract_time\n",
      "contract_type\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "l= ['id', 'created', 'location_display_name', 'country', 'state', 'county',\n",
    "       'city', 'latitude', 'longitude', 'contract_time', 'contract_type',\n",
    "       'category_tag', 'category_label', 'company_name', 'title',\n",
    "       'description', 'salary_is_predicted', 'salary_min', 'salary_max',\n",
    "       'redirect_url']\n",
    "for col in l:\n",
    "    if pd.isna(pdf[col]).sum()>0:\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c8f53a-be70-43a7-bf67-50d4b1520bf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5d2e22-00dd-44a7-bc2a-1391210384a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e91402-fcbc-4c08-91c2-1d09ef9fff33",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_locations_mask = (pdf['city'].isna()) |( pdf['county'].isna()) | (pdf['state'].isna()) |( pdf['country'].isna())\n",
    "missing_locations_longitude_latitude = pdf.loc[missing_locations_mask,['longitude','latitude']].drop_duplicates().to_records(index=False).tolist()\n",
    "get_missing_locations_longitude_latitude_dict = get_missing_locations_longitude_latitude_dict(missing_locations_longitude_latitude)\n",
    "city_col = pdf.loc[missing_locations_mask ,['longitude','latitude']].apply(lambda X: get_missing_locations_longitude_latitude_dict.get((X['longitude'],X['latitude'])).get('city'),axis=1)\n",
    "county_col = pdf.loc[missing_locations_mask ,['longitude','latitude']].apply(lambda X: get_missing_locations_longitude_latitude_dict.get((X['longitude'],X['latitude'])).get('county'),axis=1)\n",
    "state_col = pdf.loc[missing_locations_mask ,['longitude','latitude']].apply(lambda X: get_missing_locations_longitude_latitude_dict.get((X['longitude'],X['latitude'])).get('state'),axis=1)\n",
    "country_col = pdf.loc[missing_locations_mask,['longitude','latitude']].apply(lambda X: get_missing_locations_longitude_latitude_dict.get((X['longitude'],X['latitude'])).get('country'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbca9e8-ef72-4e5b-a49d-8d4d3f39fcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.loc[missing_locations_mask ,'city'],pdf.loc[missing_locations_mask ,'county'],pdf.loc[missing_locations_mask ,'state'],pdf.loc[missing_locations_mask ,'country'] =\\\n",
    "city_col,county_col,state_col,country_col"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
